<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Essential LLM Readings | Florian Bastin </title> <meta name="author" content="Florian Bastin"> <meta name="description" content="Curated list of foundational and recent papers on Large Language Models"> <meta name="keywords" content="GenAI, RAG, LLM, Daupgine Tunis"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.jpg?65c4f4ef6f7c54ebb97a7d744048083d"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://bastinflorian.github.io/readings/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Florian</span> Bastin </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Home </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Git Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item active"> <a class="nav-link" href="/readings/">Essential LLM Readings <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Essential LLM Readings</h1> <p class="post-description">Curated list of foundational and recent papers on Large Language Models</p> </header> <article> <h1 id="essential-llm-research-papers">Essential LLM Research Papers</h1> <p>A curated reading list of the most important papers in Large Language Models, organized by priority and importance.</p> <hr> <h2 id="-mandatory-readings-must-read-first">üìå Mandatory Readings (Must Read First)</h2> <p>These four papers form the absolute foundation of understanding LLMs:</p> <h3 id="1-attention-is-all-you-need-">1. <strong>Attention Is All You Need</strong> ‚≠ê‚≠ê‚≠ê</h3> <ul> <li> <strong>Authors:</strong> Vaswani et al. (2017)</li> <li> <strong>Link:</strong> <a href="https://arxiv.org/abs/1706.03762" rel="external nofollow noopener" target="_blank">arXiv</a> </li> <li> <strong>Why Essential:</strong> Introduced the Transformer architecture that underlies ALL modern LLMs. Without this paper, GPT, BERT, Claude, and other models wouldn‚Äôt exist.</li> <li> <strong>Key Concepts:</strong> Self-attention mechanism, multi-head attention, positional encoding</li> </ul> <h3 id="2-language-models-are-few-shot-learners-gpt-3-">2. <strong>Language Models are Few-Shot Learners (GPT-3)</strong> ‚≠ê‚≠ê‚≠ê</h3> <ul> <li> <strong>Authors:</strong> Brown et al., OpenAI (2020)</li> <li> <strong>Link:</strong> <a href="https://arxiv.org/abs/2005.14165" rel="external nofollow noopener" target="_blank">arXiv</a> </li> <li> <strong>Why Essential:</strong> Demonstrated that scaling + prompting = emergent capabilities. Triggered the LLM revolution and showed models can solve new tasks without fine-tuning.</li> <li> <strong>Key Concepts:</strong> In-context learning, few-shot prompting, scaling laws</li> </ul> <h3 id="3-bert-pre-training-of-deep-bidirectional-transformers-">3. <strong>BERT: Pre-training of Deep Bidirectional Transformers</strong> ‚≠ê‚≠ê‚≠ê</h3> <ul> <li> <strong>Authors:</strong> Devlin et al., Google (2018)</li> <li> <strong>Link:</strong> <a href="https://arxiv.org/abs/1810.04805" rel="external nofollow noopener" target="_blank">arXiv</a> </li> <li> <strong>Why Essential:</strong> First massively pre-trained model that revolutionized NLP. Introduced transfer learning and bidirectional context understanding.</li> <li> <strong>Key Concepts:</strong> Masked language modeling, transfer learning, bidirectional transformers</li> </ul> <h3 id="4-deepseek-r1-incentivizing-reasoning-capability-in-llms-">4. <strong>DeepSeek-R1: Incentivizing Reasoning Capability in LLMs</strong> üî•</h3> <ul> <li> <strong>Authors:</strong> DeepSeek-AI (January 2025)</li> <li> <strong>Link:</strong> <a href="https://arxiv.org/pdf/2501.12948" rel="external nofollow noopener" target="_blank">arXiv</a> </li> <li> <strong>Why Revolutionary:</strong> <ul> <li>Achieves OpenAI o1 level reasoning performance while being fully open-source</li> <li>Introduces novel reinforcement learning approach for reasoning</li> <li>Outperforms GPT-4 on mathematical and coding benchmarks</li> </ul> </li> <li> <strong>Key Innovations:</strong> GRPO (Group Relative Policy Optimization), reasoning-focused RL training</li> </ul> <hr> <h2 id="-core-papers-highly-recommended">üéØ Core Papers (Highly Recommended)</h2> <p>Essential papers for understanding modern LLM capabilities:</p> <h3 id="chain-of-thought-prompting-elicits-reasoning-"> <strong>Chain of Thought Prompting Elicits Reasoning</strong> ‚≠ê‚≠ê‚≠ê</h3> <ul> <li> <strong>Authors:</strong> Wei et al., Google (2022)</li> <li> <strong>Link:</strong> <a href="https://arxiv.org/abs/2201.11903" rel="external nofollow noopener" target="_blank">arXiv</a> </li> <li> <strong>Impact:</strong> Breakthrough in LLM reasoning, fundamental technique used everywhere today</li> </ul> <h3 id="fine-tuning-language-models-from-human-preferences-rlhf-"> <strong>Fine-Tuning Language Models from Human Preferences (RLHF)</strong> ‚≠ê‚≠ê‚≠ê</h3> <ul> <li> <strong>Authors:</strong> Ouyang et al., OpenAI (2022)</li> <li> <strong>Link:</strong> <a href="https://arxiv.org/abs/2203.02155" rel="external nofollow noopener" target="_blank">arXiv</a> </li> <li> <strong>Impact:</strong> Key to making LLMs useful and aligned, basis of ChatGPT and all conversational models</li> </ul> <hr> <h2 id="-recent-breakthroughs-2024-2025">üöÄ Recent Breakthroughs (2024-2025)</h2> <h3 id="deepseek-v3-technical-report"><strong>DeepSeek-V3 Technical Report</strong></h3> <ul> <li> <strong>Authors:</strong> DeepSeek-AI (December 2024)</li> <li> <strong>Link:</strong> <a href="https://arxiv.org/abs/2412.19437" rel="external nofollow noopener" target="_blank">arXiv</a> </li> <li> <strong>Impact:</strong> 671B parameter model trained with only $2.8M budget, achieving GPT-4 performance at fraction of cost</li> </ul> <h3 id="scaling-llm-test-time-compute-optimally"><strong>Scaling LLM Test-Time Compute Optimally</strong></h3> <ul> <li> <strong>Authors:</strong> Various (August 2024)</li> <li> <strong>Link:</strong> <a href="https://arxiv.org/abs/2408.03314" rel="external nofollow noopener" target="_blank">arXiv</a> </li> <li> <strong>Impact:</strong> New paradigm for improving LLM outputs during inference</li> </ul> <hr> <h2 id="-important-papers-recommended">üìà Important Papers (Recommended)</h2> <h3 id="scaling-and-architecture">Scaling and Architecture</h3> <ul> <li> <strong>Scaling Laws for Neural Language Models</strong> ‚≠ê‚≠ê ‚Äî Kaplan et al. (2020): <a href="https://arxiv.org/abs/2001.08361" rel="external nofollow noopener" target="_blank">arXiv</a> <ul> <li>Shows predictable performance growth with scale</li> </ul> </li> <li> <strong>LLaMA: Open and Efficient Foundation Language Models</strong> ‚≠ê‚≠ê ‚Äî Touvron et al., Meta (2023): <a href="https://arxiv.org/abs/2302.13971" rel="external nofollow noopener" target="_blank">arXiv</a> <ul> <li>Made powerful LLMs accessible to open-source community</li> </ul> </li> </ul> <h3 id="alignment-and-safety">Alignment and Safety</h3> <ul> <li> <strong>Constitutional AI: Harmlessness from AI Feedback</strong> ‚≠ê‚≠ê ‚Äî Bai et al., Anthropic (2022): <a href="https://arxiv.org/abs/2212.08073" rel="external nofollow noopener" target="_blank">arXiv</a> <ul> <li>Alternative approach to RLHF for model alignment</li> </ul> </li> </ul> <h3 id="efficiency-and-adaptation">Efficiency and Adaptation</h3> <ul> <li> <strong>LoRA: Low-Rank Adaptation of Large Language Models</strong> ‚≠ê‚≠ê ‚Äî Hu et al. (2021): <a href="https://arxiv.org/abs/2106.09685" rel="external nofollow noopener" target="_blank">arXiv</a> <ul> <li>Efficient fine-tuning method widely adopted</li> </ul> </li> <li> <strong>FlashAttention: Fast and Memory-Efficient Exact Attention</strong> ‚≠ê‚≠ê ‚Äî Dao et al. (2022): <a href="https://arxiv.org/abs/2205.14135" rel="external nofollow noopener" target="_blank">arXiv</a> <ul> <li>Key optimization for fast training/inference on GPU</li> </ul> </li> </ul> <hr> <h2 id="-additional-readings">üìö Additional Readings</h2> <h3 id="understanding-and-analysis">Understanding and Analysis</h3> <ul> <li> <strong>The Illustrated Transformer</strong> ‚≠ê ‚Äî Jay Alammar: <a href="http://jalammar.github.io/illustrated-transformer/" rel="external nofollow noopener" target="_blank">Blog</a> <ul> <li>Best visual guide to understanding Transformers</li> </ul> </li> <li> <strong>Emergent Abilities of Large Language Models</strong> ‚≠ê ‚Äî Wei et al. (2022): <a href="https://arxiv.org/abs/2206.07682" rel="external nofollow noopener" target="_blank">arXiv</a> <ul> <li>Analysis of emergent behaviors at scale</li> </ul> </li> </ul> <h3 id="scaling-examples">Scaling Examples</h3> <ul> <li> <strong>PaLM: Scaling Language Models with Pathways</strong> ‚≠ê ‚Äî Chowdhery et al., Google (2022): <a href="https://arxiv.org/abs/2204.02311" rel="external nofollow noopener" target="_blank">arXiv</a> <ul> <li>540B parameter model demonstrating extreme scaling</li> </ul> </li> </ul> <h3 id="advanced-techniques">Advanced Techniques</h3> <ul> <li> <strong>Self-Consistency Improves Chain of Thought Reasoning</strong> ‚≠ê ‚Äî Wang et al. (2022): <a href="https://arxiv.org/abs/2203.11171" rel="external nofollow noopener" target="_blank">arXiv</a> <ul> <li>Improves reasoning with multiple sampling</li> </ul> </li> <li> <strong>Toolformer: Language Models Can Teach Themselves to Use Tools</strong> ‚≠ê ‚Äî Schick et al., Meta (2023): <a href="https://arxiv.org/abs/2302.04761" rel="external nofollow noopener" target="_blank">arXiv</a> <ul> <li>LLMs learning to use APIs and external tools</li> </ul> </li> </ul> <hr> <h2 id="-reading-roadmap">üìñ Reading Roadmap</h2> <ol> <li> <strong>Start with the foundations:</strong> Read the 3 mandatory papers in order</li> <li> <strong>Understand modern capabilities:</strong> Read Chain of Thought and RLHF papers</li> <li> <strong>Explore recent breakthroughs:</strong> Study DeepSeek-V3 for understanding current SOTA</li> <li> <strong>Deep dive by interest:</strong> <ul> <li>For efficiency ‚Üí LoRA, FlashAttention</li> <li>For safety ‚Üí Constitutional AI</li> <li>For open models ‚Üí LLaMA series</li> <li>For scaling ‚Üí Scaling Laws, PaLM</li> </ul> </li> </ol> <hr> <h2 id="-quick-links">üîó Quick Links</h2> <ul> <li><a href="/teaching/">Dauphine Tunis 2025-2026 Course Materials</a></li> <li><a href="https://github.com/BastinFlorian/Langchain-Langgraph-courses" rel="external nofollow noopener" target="_blank">GitHub Repository - Langchain/Langgraph Courses</a></li> <li><a href="https://arxiv.org/list/cs.LG/recent" rel="external nofollow noopener" target="_blank">arXiv ML Papers</a></li> <li><a href="https://paperswithcode.com/" rel="external nofollow noopener" target="_blank">Papers with Code</a></li> </ul> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Florian Bastin. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: October 03, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-E6GFW5ZTBH"></script> <script defer src="/assets/js/google-analytics-setup.js"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>